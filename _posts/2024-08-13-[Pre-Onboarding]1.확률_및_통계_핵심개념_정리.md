---
layout: single
title: "[원티드_프리온보딩]1.확률 및 통계 핵심개념 정리"
categories: machine-learning
tag: [machine-learning, job-interview]
use_math: true
toc: True ##Table of contents
typora-root-url: ../ 
---



## 확률 및 통계 핵심개념 정리

### 확률 및 확률분포

#### 확률(Probability)

- **확률(Probability):** 특정 사건이 일어날 가능성을 0에서 1 사이의 값으로 나타내며, 사건이 발생할 확률이 높을수록 1에 가까워집니다.
  $$
  0 \leq P(A) \leq 1
  $$
  여기서 $ P(A) $는 사건 $ A $가 발생할 확률을 나타냅니다.
  
- **표본공간(Sample Space, $ S $):** 모든 가능한 결과의 집합입니다. 예를 들어, 주사위를 던졌을 때의 표본공간은 $\{1, 2, 3, 4, 5, 6\}$입니다.

- **사건(Event):** 표본공간의 부분집합으로, 특정한 결과나 결과들의 집합을 나타냅니다. 예를 들어, 짝수가 나오는 사건은 $\{2, 4, 6\}$입니다.

#### 확률변수와 확률분포

- **확률변수(Random Variable):** 결과를 수치적으로 나타내는 함수입니다. 주사위를 던졌을 때 나오는 수를 $ X $로 표현할 수 있습니다.

- **확률분포(Probability Distribution):** 확률변수가 취할 수 있는 모든 가능한 값에 대한 확률을 나타내는 함수입니다.

  - **이산형 확률분포(Discrete Probability Distribution):** 확률변수가 특정한 이산값을 가질 확률을 나타냅니다. 예를 들어, 동전을 던졌을 때 앞면이 나올 확률은 $\frac{1}{2}$입니다.

  - **연속형 확률분포(Continuous Probability Distribution):** 확률변수가 특정 구간 내의 실수값을 가질 확률을 나타내며, 확률밀도함수(PDF)를 통해 설명됩니다.

  $$
  P(a \leq X \leq b) = \int_{a}^{b} f(x) \, dx
  $$

  여기서 $ f(x) $는 확률밀도함수입니다.

### 우도와 최대우도추정법

#### 우도(Likelihood)

- **우도(Likelihood):** 주어진 데이터가 특정 확률 분포로부터 발생했을 가능성을 나타내는 척도로, 관측된 데이터에 대한 확률을 계산하는 데 사용됩니다. 

- 주어진 데이터 $ x_1, x_2, \ldots, x_n $의 확률 분포 $ f(x|\theta) $가 주어졌을 때, 우도는 다음과 같이 정의됩니다.

  $$
  L(\theta|x_1, x_2, \ldots, x_n) = \prod_{i=1}^{n} f(x_i|\theta)
  $$


#### 최대우도추정법(Maximum Likelihood Estimation)

- **최대우도추정법(Maximum Likelihood Estimation, MLE):** 주어진 데이터가 관측될 확률을 최대화하는 분포의 모수를 추정하는 방법입니다.

- 우도를 최대화하는 모수 $\theta$를 찾는 방법으로, 수학적으로는 다음과 같은 식을 최대화합니다.

  $$
  \hat{\theta} = \arg\max_{\theta} L(\theta|x_1, x_2, \ldots, x_n)
  $$


### 중심극한정리와 큰수의 법칙

#### 중심극한정리(Central Limit Theorem)

- **중심극한정리:** 표본의 크기가 충분히 크다면, 표본 평균의 분포는 모집단의 분포 형태와 관계없이 정규분포에 가까워진다는 이론입니다. 이는 많은 표본의 평균이 모평균에 접근한다는 것을 의미합니다.

  - **수식:** 표본 크기가 $ n $인 표본의 평균 $ \bar{X} $는 모집단의 평균 $\mu$와 분산 $\sigma^2/n$를 갖는 정규분포에 수렴합니다.

  $$
  \bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)
  $$

  

#### 큰수의 법칙(Law of Large Numbers)

- **큰수의 법칙:** 표본 크기가 커짐에 따라 표본 평균은 모집단 평균에 수렴합니다. 즉, 표본의 수가 많을수록 표본 평균은 모집단의 실제 평균에 가까워집니다.

  $$
  \lim_{n \to \infty} \bar{X}_n = \mu
  $$
여기서 $\bar{X}_n$은 표본 평균, $\mu$는 모집단 평균입니다.

### 평균, 분산, 표준편차

#### 평균(Mean)

- **평균(Mean):** 데이터의 산술적 중심값으로, 모든 관측값의 합을 관측값의 수로 나눈 값입니다.

  $$
  \bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i
  $$
여기서 $ x_i $는 각 데이터 포인트, $ n $은 데이터의 총 개수입니다.

#### 분산(Variance)

- **분산(Variance):** 각 데이터 포인트가 평균에서 얼마나 떨어져 있는지를 나타내는 척도로, 산포도의 크기를 측정합니다.

  $$
  \sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2
  $$
  표본의 분산은 다음과 같이 정의됩니다.
  
  $$
  s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2
  $$
  

#### 표준편차(Standard Deviation)

- **표준편차(Standard Deviation):** 분산의 제곱근으로, 데이터의 변동성을 원래 단위로 나타내는 척도입니다.

  $$
  \sigma = \sqrt{\sigma^2}
  $$
  표본 표준편차는 다음과 같이 정의됩니다.
  
  $$
  s = \sqrt{s^2}
  $$
  

### 정규분포와 표준화

#### 정규분포(Normal Distribution)

- **정규분포:** 데이터가 평균을 중심으로 대칭적으로 분포하는 확률분포로, 가장 흔히 사용되는 통계적 분포입니다. 확률 밀도 함수는 다음과 같습니다.

  $$
  f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
  $$

  
  - $\mu$는 평균, $\sigma^2$는 분산입니다.

- 정규분포의 그래프는 종 모양을 띄며, 중앙의 평균을 중심으로 좌우 대칭입니다.

#### 표준화(Standardization)

- **표준화:** 데이터에서 평균을 빼고 표준편차로 나눈 값을 사용하여 데이터를 표준정규분포로 변환하는 과정입니다.
  $$
  Z = \frac{X - \mu}{\sigma}
  $$
  여기서 $ Z $는 표준화된 변수, $ X $는 원래 데이터, $\mu$는 평균, $\sigma$는 표준편차입니다.
  
- 표준정규분포는 평균이 0이고, 표준편차가 1인 정규분포입니다.

### 가설 검정

#### 가설 검정의 개념

- **가설 검정:** 통계적 방법을 사용하여 표본 데이터로부터 모집단에 대한 가설을 검증하는 절차입니다.

#### 귀무가설과 대립가설

- **귀무가설(Null Hypothesis, $ H_0 $):** 연구나 실험에서 기본적으로 채택되는 가설로, 변화가 없음을 가정합니다. 예를 들어, "동전의 앞면이 나올 확률은 50%이다."

- **대립가설(Alternative Hypothesis, $ H_1 $):** 귀무가설과 반대되는 가설로, 연구자가 증명하고자 하는 가설입니다. 예를 들어, "동전의 앞면이 나올 확률은 50%가 아니다."

- #### 검정 통계량과 유의 수준

  - **검정 통계량(Test Statistic):** 귀무가설이 참일 때 표본에서 관찰된 데이터를 요약한 값으로, 이를 통해 가설을 검정합니다.
  - **유의 수준(Significance Level, $\alpha$):** 귀무가설이 참일 때, 그것을 기각할 확률로 일반적으로 0.05가 사용됩니다.
  - **p-값(p-value):** 검정 통계량이 관측된 값보다 극단적인 값을 가질 확률로, $ p $-값이 $\alpha$보다 작으면 귀무가설을 기각합니다.

  ### 회귀 분석 (Regression Analysis)

  #### 회귀 분석의 개념

  - **회귀 분석:** 두 변수 간의 관계를 분석하여 예측 모델을 만드는 통계 기법입니다.

  #### 단순 선형회귀(Simple Linear Regression)

  - **단순 선형회귀:** 독립 변수와 종속 변수 사이의 선형 관계를 분석하는 방법으로, 하나의 독립 변수를 사용하여 결과를 예측합니다.

    - **회귀식:**

    $$
    y=ax+by = ax + by=ax+b
    $$

    여기서 $ a $는 기울기(회귀계수), $ b $는 절편이며, $ y $는 예측된 종속 변수 값입니다.

    - **목표:** 관측된 데이터와 회귀 직선 사이의 차이가 최소가 되도록 회귀계수를 추정하는 것입니다.

  #### 최소 제곱법(Ordinary Least Squares, OLS)

  - **최소 제곱법(OLS):** 회귀 분석에서 잔차(실제 관측값과 예측값의 차이)를 최소화하여 회귀계수를 추정하는 방법입니다.

    - **잔차(Residual):** 회귀모형의 예측값과 실제 관측값 간의 차이입니다.
    - **잔차 제곱의 합을 최소화:** 잔차의 제곱합이 최소가 되는 기울기와 절편을 찾아냅니다.

    $$
    \text{Sum of Squared Residuals} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    $$

    여기서 $ y_i $는 실제 값, $\hat{y}_i$는 예측된 값입니다.