---
layout: single
title: "[혼공머신]2-2"
categories: machine-learning
tag: [python, machine-learning]
toc: True #Table of contents
typora-root-url: ../
---

## [혼공머신]2-2

### 데이터 전처리 및 핵심 패키지와 함수

#### 데이터 전처리
데이터 전처리는 머신러닝 모델에 훈련 데이터를 주입하기 전에 가공하는 단계를 말합니다. 데이터 전처리에는 결측값 처리, 데이터 정규화, 이상치 제거 등이 포함됩니다. 때로는 데이터 전처리에 많은 시간이 소모되기도 합니다.

- **표준점수**: 표준점수는 훈련 세트의 스케일을 바꾸는 대표적인 방법 중 하나입니다. 표준점수를 얻으려면 특성의 평균을 빼고 표준편차로 나눕니다. 이 때 반드시 훈련 세트의 평균과 표준편차로 테스트 세트를 변환해야 합니다.

#### 핵심 개념
- **브로드캐스팅**: 크기가 다른 넘파이 배열에서 자동으로 사칙 연산을 모든 행이나 열로 확장하여 수행하는 기능입니다.

### 핵심 패키지와 함수

#### scikit-learn
1. **train_test_split( )**
   - 훈련 데이터를 훈련 세트와 테스트 세트로 나누는 함수입니다.
   - 여러 개의 배열을 전달할 수 있으며, 테스트 세트로 나눌 비율은 `test_size` 매개변수에서 지정할 수 있습니다. 기본값은 0.25 (25%)입니다.
   - `shuffle` 매개변수로 훈련 세트와 테스트 세트로 나누기 전에 무작위로 섞을지 여부를 결정할 수 있으며 기본값은 True입니다.
   - `stratify` 매개변수에 클래스 레이블이 담긴 배열(일반적으로 타깃 데이터)을 전달하면 클래스 비율에 맞게 훈련 세트와 테스트 세트를 나눌 수 있습니다.

2. **kneighbors( )**
   - `k-최근접 이웃` 객체의 메서드로, 입력한 데이터에 가장 가까운 이웃을 찾아 거리와 이웃 샘플의 인덱스를 반환합니다.
   - 이웃의 개수는 `KNeighborsClassifier` 클래스의 객체를 생성할 때 지정한 개수를 사용하며, `n_neighbors` 매개변수에서 다르게 지정할 수도 있습니다.
   - `return_distance` 매개변수를 False로 지정하면 이웃 샘플의 인덱스만 반환하고 거리는 반환하지 않습니다. 기본값은 True입니다.

### 데이터 전처리 예시 코드
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

# 데이터 생성
X, y = np.random.rand(100, 2), np.random.randint(0, 2, 100)

# 훈련 세트와 테스트 세트로 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, stratify=y)

# 데이터 스케일링
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# k-최근접 이웃 모델 훈련
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_scaled, y_train)

# 새로운 데이터 포인트 예측
new_data = np.array([[0.5, 0.5]])
new_data_scaled = scaler.transform(new_data)
distances, indexes = knn.kneighbors(new_data_scaled)

# 시각화
plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], label='Training Data')
plt.scatter(new_data_scaled[0, 0], new_data_scaled[0, 1], label='New Data', marker='^')
plt.scatter(X_train_scaled[indexes, 0], X_train_scaled[indexes, 1], label='Neighbors', marker='D')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()
```

### 요약
- 데이터 전처리는 머신러닝 모델의 성능을 높이는 중요한 단계입니다.
- 표준점수와 브로드캐스팅 같은 개념을 이해하면 데이터 전처리를 더 효율적으로 수행할 수 있습니다.
- scikit-learn 패키지의 `train_test_split`과 `kneighbors` 함수는 데이터 분할과 모델 학습에 유용합니다.

이 자료를 통해 데이터 전처리의 중요성과 scikit-learn을 활용한 데이터 전처리 방법을 이해할 수 있을 것입니다.